{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas padrão\n",
    "import os\n",
    "\n",
    "# Importação de bibliotecas para manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importação de bibliotecas para visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importação de bibliotecas de aprendizado de máquina\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, learning_curve\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix as sk_confusion_matrix, ConfusionMatrixDisplay, f1_score, classification_report, make_scorer\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Importação de bibliotecas adicionais\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint, loguniform, uniform\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Importação de datasets de exemplo do scikit-learn\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escolha do Modelo de ML\n",
    "\n",
    "modelo = SVC()\n",
    "#modelo =  KNeighborsClassifier()\n",
    "#modelo = RandomForestClassifier()\n",
    "#modelo = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Região de Interesse do espectro Raman\n",
    "\n",
    "regiao = '1'\n",
    "#regiao = '2'\n",
    "#regiao = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o diretório onde estão os arquivos de espectros Raman\n",
    "diretorio_raiz = 'c:/Users/Andreia/Jupyter/TCC/elementos/R' + regiao\n",
    "\n",
    "# Listar os diretórios (tipos de plástico)\n",
    "diretorios_plasticos = [diretorio for diretorio in os.listdir(diretorio_raiz) if os.path.isdir(os.path.join(diretorio_raiz, diretorio))]\n",
    "\n",
    "# Inicializar listas para armazenar todos os dados e rótulos\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "# Para cada tipo de plástico\n",
    "for idx, plastico in enumerate(diretorios_plasticos):\n",
    "    diretorio_plastico = os.path.join(diretorio_raiz, plastico)\n",
    "    arquivos_plastico = os.listdir(diretorio_plastico)\n",
    "\n",
    "    # Inicializar listas para armazenar dados de cada tipo de plástico\n",
    "    folder_data = []\n",
    "    folder_labels = []\n",
    "\n",
    "    # Para cada arquivo de espectro Raman\n",
    "    for arquivo in arquivos_plastico:\n",
    "        # Lendo o arquivo de espectro Raman\n",
    "        caminho_arquivo = os.path.join(diretorio_plastico, arquivo)\n",
    "\n",
    "        # Carregando os dados do arquivo\n",
    "        espectro = np.loadtxt(caminho_arquivo, delimiter='\\t', dtype='str')\n",
    "\n",
    "        # Adicionar espectro e rótulo às listas\n",
    "        folder_data.append(espectro)\n",
    "        folder_labels.append(plastico)\n",
    "\n",
    "    # Adicionar dados e rótulos deste tipo de plástico às listas totais\n",
    "    all_data.extend(folder_data)\n",
    "    all_labels.extend(folder_labels)\n",
    "\n",
    "# Dividir os dados totais em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.3, random_state=42, stratify=all_labels)\n",
    "\n",
    "# Transformar os dados em arrays numpy\n",
    "train_data = np.array(X_train)\n",
    "train_labels = np.array(y_train)\n",
    "test_data = np.array(X_test)\n",
    "test_labels = np.array(y_test)\n",
    "\n",
    "# Verificar a forma original dos dados\n",
    "print(\"Forma original dos dados de treinamento:\", train_data.shape)\n",
    "print(\"Forma original dos dados de teste:\", test_data.shape)\n",
    "\n",
    "# Extrair comprimentos de onda e intensidades\n",
    "train_data_reshaped = train_data[:, :, 1]\n",
    "test_data_reshaped = test_data[:, :, 1]\n",
    "\n",
    "# Verificar a forma dos dados ajustados\n",
    "print(\"Forma ajustada dos dados de treinamento:\", train_data.shape)\n",
    "\n",
    "# Inicializar o codificador de rótulos\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar o codificador aos rótulos de treino e transformá-los em valores numéricos\n",
    "y_encoded_train = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Transformar os rótulos de teste usando o mesmo codificador\n",
    "y_encoded_test = label_encoder.transform(test_labels)\n",
    "\n",
    "# Converter os arrays numpy em DataFrames\n",
    "train_data = pd.DataFrame(train_data_reshaped)\n",
    "train_labels = pd.DataFrame(y_encoded_train, columns=[\"Label\"])\n",
    "test_data = pd.DataFrame(test_data_reshaped)\n",
    "test_labels = pd.DataFrame(y_encoded_test, columns=[\"Label\"])\n",
    "\n",
    "# Verificar a forma final dos DataFrames\n",
    "print(\"Forma final dos dados de treinamento (DataFrame):\", train_data.shape)\n",
    "print(\"Forma final dos rótulos de treinamento (DataFrame):\", train_labels.shape)\n",
    "print(\"Forma final dos dados de teste (DataFrame):\", test_data.shape)\n",
    "print(\"Forma final dos rótulos de teste (DataFrame):\", test_labels.shape)\n",
    "\n",
    "# Mostrar o valor de cada número e o significado dele\n",
    "class_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(\"\\nMapeamento de cada número codificado para a classe original:\")\n",
    "for encoded_value, original_class in class_mapping.items():\n",
    "    print(f\"{encoded_value}: {original_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzir dimensionalidade dos dados de treinamento\n",
    "pca = PCA(n_components=15) \n",
    "#R2 = 80, R1 = 20\n",
    "train_data_pca = pca.fit_transform(train_data_reshaped)\n",
    "test_data_pca = pca.transform(test_data_reshaped)\n",
    "\n",
    "# Converter os arrays numpy em DataFrames\n",
    "train_data_pca = pd.DataFrame(train_data_pca)\n",
    "test_data_pca = pd.DataFrame(test_data_pca )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para otimizar os hiperparâmetros é feito um treinamento com a técnica Cross Validation\n",
    "\n",
    "\n",
    "def validacao_cruzada(modelo, x, y, oversampling=False, diretorios_plasticos=None):\n",
    "    # Inicializar o StratifiedKFold\n",
    "    kfold = StratifiedKFold(n_splits=3)\n",
    "    acuracias_split = []\n",
    "    f1_scores_split = []\n",
    "    confusoes_split = []\n",
    "\n",
    "    for idx, (idx_treino, idx_validacao) in enumerate(kfold.split(x, y)):\n",
    "        x_split_treino = x.iloc[idx_treino]\n",
    "        y_split_treino = y.iloc[idx_treino].values.ravel()  # Converter para array unidimensional\n",
    "        x_split_validacao = x.iloc[idx_validacao]\n",
    "        y_split_validacao = y.iloc[idx_validacao].values.ravel()  # Converter para array unidimensional\n",
    "\n",
    "        if oversampling:\n",
    "            sm = SMOTE(random_state=42, k_neighbors=1)\n",
    "            x_split_treino, y_split_treino = sm.fit_resample(x_split_treino, y_split_treino)\n",
    "\n",
    "        # Treinar o modelo\n",
    "        modelo.fit(x_split_treino, y_split_treino)\n",
    "\n",
    "        # Fazer previsões\n",
    "        y_pred = modelo.predict(x_split_validacao)\n",
    "\n",
    "        # Calcular a acurácia e F1-score\n",
    "        acuracia_split = accuracy_score(y_split_validacao, y_pred)\n",
    "        f1_split = f1_score(y_split_validacao, y_pred, average='weighted')\n",
    "\n",
    "        # Adicionar as métricas à lista\n",
    "        acuracias_split.append(acuracia_split)\n",
    "        f1_scores_split.append(f1_split)\n",
    "\n",
    "        # Imprimir a acurácia do split atual\n",
    "        print(f\"Acurácia do split {idx + 1}: {acuracia_split:.4f}\")\n",
    "        print(f\"F1-score do split {idx + 1}: {f1_split:.4f}\")\n",
    "\n",
    "        # Imprimir quantidade de amostras por classe\n",
    "        #print(\"Distribuição das classes no conjunto de treino:\")\n",
    "        #print(pd.Series(y_split_treino).value_counts())\n",
    "        #print(\"Distribuição das classes no conjunto de validação:\")\n",
    "        #print(pd.Series(y_split_validacao).value_counts())\n",
    "\n",
    "    return acuracias_split, f1_scores_split, confusoes_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir o espaço de hiperparâmetros para o modelo base, EXEMPLO.\n",
    "param_dist = {\n",
    "    'estimator__C': loguniform(0.1, 10),  # Distribuição log-uniforme para C\n",
    "    'estimator__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Diferentes tipos de kernel\n",
    "    'estimator__gamma': loguniform(1e-4, 1e-1),  # Distribuição log-uniforme para gamma\n",
    "    'estimator__degree': randint(1, 10),  # Distribuição discreta para o grau do kernel polinomial\n",
    "    'estimator__coef0': uniform(-1, 1)  # Distribuição uniforme para coef0\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar o RandomizedSearchCV com o OneVsRestClassifier\n",
    "random_search = RandomizedSearchCV(\n",
    "    modelo,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ajustar o RandomizedSearchCV com os dados de treinamento\n",
    "random_search.fit(train_data_pca, train_labels)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros (Random Search): \", random_search.best_params_)\n",
    "print(\"Acurácia (Random Search): \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o espaço de hiperparâmetros para busca, EXEMPLO\n",
    "param_space = {\n",
    "    'n_estimators': Integer(10, 200),  # número de árvores\n",
    "    'criterion': Categorical(['gini', 'entropy']),  # função de critério\n",
    "    'max_depth': Integer(1, 20),  # profundidade máxima\n",
    "    'min_samples_split': Integer(2, 20),  # número mínimo de amostras para dividir\n",
    "    'min_samples_leaf': Integer(1, 20)  # número mínimo de amostras para folha\n",
    "}\n",
    "\n",
    "# Realizar o Bayesian Search\n",
    "bayes_search = BayesSearchCV(modelo, search_spaces=param_space, n_iter=50, cv=3, random_state=42, n_jobs=-1)\n",
    "bayes_search.fit(train_data_pca, train_labels)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros (Bayesian Search): \", bayes_search.best_params_)\n",
    "print(\"Acurácia (Bayesian Search): \", bayes_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Após definidos os hiperparâmetros, treinar o modelo com base neles\n",
    "\n",
    "# Definir o espaço de hiperparâmetros para busca EXEMPLO\n",
    "best_modelo = KNeighborsClassifier(\n",
    "    n_neighbors= 10,\n",
    "    weights= 'uniform',\n",
    "    algorithm= 'auto', #'ball_tree', 'kd_tree', 'brute',\n",
    "    p= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a função de validação simples\n",
    "def validacao_simples(modelo, x_train, y_train, x_val, y_val, oversampling=False, diretorios_plasticos=None):\n",
    "    # Se necessário, aplicar oversampling no conjunto de treino\n",
    "    if oversampling:\n",
    "        sm = SMOTE(random_state=42, k_neighbors=5)\n",
    "        x_train, y_train = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "    # Treinar o modelo\n",
    "    modelo.fit(x_train, y_train)\n",
    "\n",
    "    # Fazer previsões no conjunto de validação\n",
    "    y_pred = modelo.predict(x_val)\n",
    "\n",
    "    # Calcular a acurácia e F1-score\n",
    "    acuracia = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "    # Imprimir a acurácia e F1-score\n",
    "    print(f\"Acurácia: {acuracia:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    # Imprimir matriz de confusão e relatório de classificação\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    cm = sk_confusion_matrix(y_val, y_pred)\n",
    "    print(cm)\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    return acuracia, f1, cm\n",
    "\n",
    "\n",
    "diretorios_plasticoscm = ['ABS', 'PA', 'PC', 'PE', 'PES', 'PET', 'PMMA', 'PP', 'PS', 'PTFE', 'PU', 'PVC']\n",
    "# Chamar a função de validação simples e armazenar os resultados\n",
    "acuracia, f1, cm = validacao_simples(best_modelo, train_data_pca, train_labels, test_data_pca, test_labels, oversampling=True, diretorios_plasticos=diretorios_plasticoscm)\n",
    "\n",
    "# Verificar a forma da matriz de confusão\n",
    "print(f\"Forma da matriz de confusão: {cm.shape}\")\n",
    "\n",
    "# Exibir matriz de confusão\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=diretorios_plasticoscm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.xlabel('Classe Prevista')\n",
    "plt.ylabel('Classe Verdadeira')\n",
    "plt.xticks(rotation=90)  # Girar rótulos do eixo x para a vertical\n",
    "plt.show()  # Garante que a matriz de confusão será exibida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curva de aprendizado para detectar overfitting\n",
    "\n",
    "# Definição da função de acurácia\n",
    "scoring = make_scorer(accuracy_score)\n",
    "\n",
    "# Cálculo da curva de aprendizado\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_modelo, train_data_pca, train_labels, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10), scoring=scoring\n",
    ")\n",
    "\n",
    "# Calculando a média e o desvio padrão das pontuações de treinamento e teste\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plotagem\n",
    "plt.figure()\n",
    "plt.title(\"Curva de Aprendizado para o KNN\")\n",
    "plt.xlabel(\"Tamanho do Conjunto de Treinamento\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.grid()\n",
    "\n",
    "# Preenchendo a área ao redor da linha para erro padrão\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "# Plotando as linhas médias\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Treinamento\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Teste\")\n",
    "plt.ylim(0,1.2)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
